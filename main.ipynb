{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.layers.core import Flatten\n",
    "import keras\n",
    "import h5py\n",
    "import os\n",
    "import graphviz\n",
    "import pydot\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from mosek.fusion import *\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 72\n",
    "shape = [seq_len, 19, 1]\n",
    "neurons = [256, 256, 32, 1]\n",
    "dropout = 0.3\n",
    "decay = 0.3\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"Data\")\n",
    "#os.chdir(\"/Users/michelcassard/Dropbox (MIT)/15.960 Independant Study/Data\")\n",
    "file = 'FX-5-merg.xlsx'\n",
    "# Load spreadsheet\n",
    "xl = pd.ExcelFile(file)\n",
    "close = pd.ExcelFile('close.xlsx')\n",
    "df_close=np.array(close.parse(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name, ma=[],bollinger=[],exp_ma=[],ma_conv=[]):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \n",
    "    \"\"\"\n",
    "    df = xl.parse(stock_name)\n",
    "    #df.drop(['VOLUME'], 1, inplace=True)\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Renaming all the columns so that we can use the old version code\n",
    "    df.rename(columns={'OPEN': 'Open', 'HIGH': 'High', 'LOW': 'Low', 'NUMBER_TICKS': 'Volume', 'LAST_PRICE': 'Adj Close'}, inplace=True)\n",
    "     # Percentage change\n",
    "    df['Pct'] = df['Adj Close'].pct_change()\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Moving Average    \n",
    "    if ma != []:\n",
    "        for moving in ma:\n",
    "            df['{}ma'.format(moving)] = df['Adj Close'].rolling(window=moving).mean()\n",
    "    # Bollinger   \n",
    "    if bollinger != []:\n",
    "        def bbands(price, length=30, numsd=2):\n",
    "            \"\"\" returns average, upper band, and lower band\"\"\"\n",
    "            ave = pd.stats.moments.rolling_mean(price,length)\n",
    "            sd = pd.stats.moments.rolling_std(price,length)\n",
    "            upband = ave + (sd*numsd)\n",
    "            dnband = ave - (sd*numsd)\n",
    "            return np.round(upband,3), np.round(dnband,3)\n",
    "        for moving in bollinger:\n",
    "            df['{}bollingerup'.format(moving)],df['{}bollingerdown'.format(moving)] = bbands(df['Adj Close'], length=moving, numsd=2)\n",
    "        \n",
    "    # Exponential Moving Average    \n",
    "    if exp_ma != []:\n",
    "        for moving in exp_ma:\n",
    "            df['{}exp_ma'.format(moving)] = df['Adj Close'].ewm(min_periods=1, adjust=True,com=moving).mean()\n",
    "   \n",
    "    # Moving Average Convergence   \n",
    "    if ma_conv!= []:\n",
    "        for moving in ma_conv:\n",
    "            df['{}ma_conv'.format(moving)] = df['Adj Close'].ewm(min_periods=1, adjust=True,com=moving[0]).mean()-df['Adj Close'].ewm(min_periods=1, adjust=True,com=moving[1]).mean()\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "  \n",
    "    # Move Adj Close to the rightmost for the ease of training\n",
    "    adj_close = df['Adj Close']\n",
    "    df.drop(labels=['Adj Close'], axis=1, inplace=True)\n",
    "    df = pd.concat([df, adj_close], axis=1)\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock(df):\n",
    "    print(df.head())\n",
    "    plt.subplot(211)\n",
    "    plt.plot(df['Adj Close'], color='red', label='Adj Close')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(212)\n",
    "    plt.plot(df['Pct'], color='blue', label='Percentage change')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock,normalize,seq_len,split,ma=[],bollinger=[],exp_ma=[],ma_conv=[]):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    print (\"Amount of features = {}\".format(amount_of_features))\n",
    "    sequence_length = seq_len+1\n",
    "    result_train = []\n",
    "    result_test= []\n",
    "    row = round(split * stock.shape[0])\n",
    "    df_train=stock[0:row].copy()\n",
    "    print (\"Amount of training data = {}\".format(df_train.shape[0]))\n",
    "    df_test=stock[row:len(stock)].copy()\n",
    "    print (\"Amount of testing data = {}\".format(df_test.shape[0]))\n",
    "\n",
    "\n",
    "    if normalize:\n",
    "        #Training\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        min_max_scaler.fit(df_train['Adj Close'].values.reshape(-1,1))\n",
    "        df_train['Open'] = min_max_scaler.transform(df_train['Open'].values.reshape(-1,1))\n",
    "        df_train['High'] = min_max_scaler.transform(df_train['High'].values.reshape(-1,1))\n",
    "        df_train['Low'] = min_max_scaler.transform(df_train['Low'].values.reshape(-1,1))\n",
    "        df_train['Adj Close'] = min_max_scaler.transform(df_train['Adj Close'].values.reshape(-1,1))\n",
    "        df_train['Volume'] = min_max_scaler.fit_transform(df_train.Volume.values.reshape(-1,1))\n",
    "        df_train['Pct'] = min_max_scaler.fit_transform(df_train['Pct'].values.reshape(-1,1))\n",
    "        if ma != []:\n",
    "            for moving in ma:\n",
    "                df_train['{}ma'.format(moving)] = min_max_scaler.fit_transform(df_train['{}ma'.format(moving)].values.reshape(-1,1))\n",
    "        if bollinger != []:\n",
    "            for moving in bollinger:\n",
    "                df_train['{}bollingerup'.format(moving)] = min_max_scaler.fit_transform(df_train['{}bollingerup'.format(moving)].values.reshape(-1,1))\n",
    "                df_train['{}bollingerdown'.format(moving)] = min_max_scaler.fit_transform(df_train['{}bollingerdown'.format(moving)].values.reshape(-1,1))\n",
    "        if exp_ma != []:\n",
    "            for moving in exp_ma:\n",
    "                df_train['{}exp_ma'.format(moving)] = min_max_scaler.fit_transform(df_train['{}exp_ma'.format(moving)].values.reshape(-1,1))\n",
    "        if ma_conv!= []:\n",
    "            for moving in ma_conv:\n",
    "                df_train['{}ma_conv'.format(moving)] = min_max_scaler.fit_transform(df_train['{}ma_conv'.format(moving)].values.reshape(-1,1))\n",
    "                \n",
    "        #Test\n",
    "        min_max_scaler.fit(df_test['Adj Close'].values.reshape(-1,1))\n",
    "        df_test['Open'] = min_max_scaler.transform(df_test['Open'].values.reshape(-1,1))\n",
    "        df_test['High'] = min_max_scaler.transform(df_test['High'].values.reshape(-1,1))\n",
    "        df_test['Low'] = min_max_scaler.transform(df_test['Low'].values.reshape(-1,1))\n",
    "        df_test['Adj Close'] = min_max_scaler.transform(df_test['Adj Close'].values.reshape(-1,1))\n",
    "        df_test['Volume'] = min_max_scaler.fit_transform(df_test.Volume.values.reshape(-1,1))\n",
    "        df_test['Pct'] = min_max_scaler.fit_transform(df_test['Pct'].values.reshape(-1,1))\n",
    "        if ma != []:\n",
    "            for moving in ma:\n",
    "                df_test['{}ma'.format(moving)] = min_max_scaler.fit_transform(df_test['{}ma'.format(moving)].values.reshape(-1,1))\n",
    "        if bollinger != []:\n",
    "            for moving in bollinger:\n",
    "                df_test['{}bollingerup'.format(moving)] = min_max_scaler.fit_transform(df_test['{}bollingerup'.format(moving)].values.reshape(-1,1))\n",
    "                df_test['{}bollingerdown'.format(moving)] = min_max_scaler.fit_transform(df_test['{}bollingerdown'.format(moving)].values.reshape(-1,1))\n",
    "        if exp_ma != []:\n",
    "            for moving in exp_ma:\n",
    "                df_test['{}exp_ma'.format(moving)] = min_max_scaler.fit_transform(df_test['{}exp_ma'.format(moving)].values.reshape(-1,1))\n",
    "        if ma_conv!= []:\n",
    "            for moving in ma_conv:\n",
    "                df_test['{}ma_conv'.format(moving)] = min_max_scaler.fit_transform(df_test['{}ma_conv'.format(moving)].values.reshape(-1,1))\n",
    "                \n",
    "    #Training\n",
    "    data_train = df_train.as_matrix()\n",
    "    for index in range(len(data_train) - sequence_length):\n",
    "        result_train.append(data_train[index: index + sequence_length])\n",
    "    train = np.array(result_train)\n",
    "    X_train = train[:, :-1].copy() # all data until day m\n",
    "    y_train = train[:, -1][:,-1].copy() # day m + 1 adjusted close price\n",
    "\n",
    "    #Test\n",
    "    data_test = df_test.as_matrix()\n",
    "    for index in range(len(data_test) - sequence_length):\n",
    "        result_test.append(data_test[index: index + sequence_length])\n",
    "    test = np.array(result_test)\n",
    "    X_test = test[:, :-1].copy()\n",
    "    y_test = test[:, -1][:,-1].copy()\n",
    "\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(shape, neurons, dropout, decay):\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(Dense(neurons[0],activation=\"relu\", input_shape=(shape[0], shape[1])))\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(shape[0], shape[1]), return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons[1], input_shape=(shape[0], shape[1]), return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))\n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    \n",
    "    adam = keras.optimizers.Adam(decay=decay)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_CNN(shape, neurons, dropout, decay):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(input_shape = (shape[0], shape[1]), \n",
    "                        nb_filter=64,\n",
    "                        filter_length=2,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "    model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "    model.add(Convolution1D(input_shape = (shape[0], shape[1]), \n",
    "                        nb_filter=64,\n",
    "                        filter_length=2,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "    model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(250))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    adam = keras.optimizers.Adam(decay=decay)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(72, 19), activation=\"relu\", filters=64, kernel_size=2, strides=1, padding=\"valid\")`\n",
      "  \n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(72, 19), activation=\"relu\", filters=64, kernel_size=2, strides=1, padding=\"valid\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model_CNN(shape, neurons, dropout, decay)\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-bd02f7691bda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbollinger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexp_ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mma_conv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(df,True,seq_len,split,ma,bollinger,exp_ma,ma_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-395c12147835>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=512,epochs=epochs,validation_split=0.3,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b48c2001a7e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    print(mean(percentage_diff))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_norm(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "    newp=normalized_value_p\n",
    "    newy_test=normalized_value_y_test\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format(stock_name))\n",
    "    plt2.xlabel('5 Min ahead Forecast')\n",
    "    plt2.ylabel('Price')\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(stock_name, normalized_value,split=0.7,predict=True):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \"\"\"\n",
    "    df = xl.parse(stock_name)\n",
    "    #df.drop(['VOLUME'], 1, inplace=True)\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Renaming all the columns so that we can use the old version code\n",
    "    df.rename(columns={'OPEN': 'Open', 'HIGH': 'High', 'LOW': 'Low', 'NUMBER_TICKS': 'Volume', 'LAST_PRICE': 'Adj Close'}, inplace=True)\n",
    "\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df = df['Adj Close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    row = round(split * df.shape[0]) \n",
    "    if predict:\n",
    "        df_p=df[0:row].copy()\n",
    "    else:\n",
    "        df_p=df[row:len(df)].copy()\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    max_df=np.max(df_p)\n",
    "    min_df=np.min(df_p)\n",
    "    new=normalized_value*(max_df-min_df)+min_df\n",
    "      \n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Portfolio construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio(currency_list,file = 'FX-5-merg.xlsx',seq_len = 144,shape = [seq_len, 19, 1],neurons = [256, 256, 32, 1],dropout = 0.3,decay = 0.5,\n",
    "              epochs = 90,ma=[50, 100, 200],bollinger=[50, 100, 200],exp_ma=[50, 100, 200],ma_conv=[[26,12]],split=0.7):\n",
    "    i=0\n",
    "    mini=99999999\n",
    "    for currency in currency_list:\n",
    "        df=get_stock_data(currency, ma,bollinger,exp_ma,ma_conv)\n",
    "        X_train, y_train, X_test, y_test = load_data(df,True,seq_len,split,ma,bollinger,exp_ma,ma_conv)\n",
    "        model = build_model_CNN(shape, neurons, dropout, decay)\n",
    "        model.fit(X_train,y_train,batch_size=512,epochs=epochs,validation_split=0.3,verbose=1)\n",
    "        p = percentage_difference(model, X_test, y_test)\n",
    "        newp = denormalize(currency, p,predict=True)\n",
    "        if mini>p.size:\n",
    "            mini=p.size\n",
    "        if i==0:\n",
    "            predict=newp.copy()\n",
    "        else:\n",
    "            predict=np.hstack((predict[0:mini],newp[0:mini]))\n",
    "        i+=1\n",
    "    return predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=12,center=False).mean()\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: pd.rolling_std is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=12,center=False).std()\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=72,center=False).mean()\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: pd.rolling_std is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=72,center=False).std()\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=144,center=False).mean()\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: pd.rolling_std is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=144,center=False).std()\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(72, 19), activation=\"relu\", filters=64, kernel_size=2, strides=1, padding=\"valid\")`\n",
      "  \n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(72, 19), activation=\"relu\", filters=64, kernel_size=2, strides=1, padding=\"valid\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\ishan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 7s 758us/step - loss: 0.1450 - acc: 1.0435e-04 - val_loss: 0.0080 - val_acc: 2.4349e-04\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 5s 479us/step - loss: 0.0078 - acc: 1.0435e-04 - val_loss: 0.0073 - val_acc: 2.4349e-04\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0047 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0038 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0032 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0029 - acc: 1.0435e-04 - val_loss: 0.0025 - val_acc: 2.4349e-04\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0026 - acc: 1.0435e-04 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0025 - acc: 1.0435e-04 - val_loss: 0.0012 - val_acc: 2.4349e-04\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0023 - acc: 1.0435e-04 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0022 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 4s 465us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0031 - val_acc: 2.4349e-04\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 5s 492us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0026 - val_acc: 2.4349e-04\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0019 - acc: 1.0435e-04 - val_loss: 0.0025 - val_acc: 2.4349e-04\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 467us/step - loss: 0.0018 - acc: 1.0435e-04 - val_loss: 0.0035 - val_acc: 2.4349e-04\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0049 - val_acc: 2.4349e-04\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 0.0040 - val_acc: 2.4349e-04\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0058 - val_acc: 2.4349e-04\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 5s 485us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 0.0044 - val_acc: 2.4349e-04\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0069 - val_acc: 2.4349e-04\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 0.0026 - val_acc: 2.4349e-04\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0061 - val_acc: 2.4349e-04\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0034 - val_acc: 2.4349e-04\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 0.0056 - val_acc: 2.4349e-04\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 0.0047 - val_acc: 2.4349e-04\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 0.0040 - val_acc: 2.4349e-04\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 0.0047 - val_acc: 2.4349e-04\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 453us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 0.0054 - val_acc: 2.4349e-04\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0048 - val_acc: 2.4349e-04\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0061 - val_acc: 2.4349e-04\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0063 - val_acc: 2.4349e-04\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0030 - val_acc: 2.4349e-04\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0050 - val_acc: 2.4349e-04\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 5s 491us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0053 - val_acc: 2.4349e-04\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 5s 500us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0043 - val_acc: 2.4349e-04\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 5s 503us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0059 - val_acc: 2.4349e-04\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 6s 600us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0031 - val_acc: 2.4349e-04\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 5s 531us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0043 - val_acc: 2.4349e-04\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 6s 607us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0062 - val_acc: 2.4349e-04\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 6s 608us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0041 - val_acc: 2.4349e-04\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 8s 876us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0049 - val_acc: 2.4349e-04\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 7s 750us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0035 - val_acc: 2.4349e-04\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 5s 542us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0026 - val_acc: 2.4349e-04\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 6s 664us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0031 - val_acc: 2.4349e-04\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 7s 771us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0039 - val_acc: 2.4349e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 7s 730us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0043 - val_acc: 2.4349e-04\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 5s 486us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0031 - val_acc: 2.4349e-04\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 5s 479us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0045 - val_acc: 2.4349e-04\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0027 - val_acc: 2.4349e-04\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0035 - val_acc: 2.4349e-04\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0010 - acc: 1.0435e-04 - val_loss: 0.0034 - val_acc: 2.4349e-04\n",
      "-68.82275256644238\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 6s 614us/step - loss: 0.1351 - acc: 1.0435e-04 - val_loss: 0.0044 - val_acc: 2.4349e-04\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0127 - acc: 1.0435e-04 - val_loss: 0.0032 - val_acc: 2.4349e-04\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0084 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0070 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0059 - acc: 1.0435e-04 - val_loss: 0.0041 - val_acc: 2.4349e-04\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0050 - acc: 1.0435e-04 - val_loss: 0.0039 - val_acc: 2.4349e-04\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0043 - acc: 1.0435e-04 - val_loss: 0.0030 - val_acc: 2.4349e-04\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0042 - acc: 1.0435e-04 - val_loss: 0.0026 - val_acc: 2.4349e-04\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0041 - acc: 1.0435e-04 - val_loss: 0.0028 - val_acc: 2.4349e-04\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0039 - acc: 1.0435e-04 - val_loss: 0.0023 - val_acc: 2.4349e-04\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 5s 476us/step - loss: 0.0036 - acc: 1.0435e-04 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0037 - acc: 1.0435e-04 - val_loss: 0.0026 - val_acc: 2.4349e-04\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 5s 475us/step - loss: 0.0035 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 5s 483us/step - loss: 0.0035 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 5s 470us/step - loss: 0.0035 - acc: 1.0435e-04 - val_loss: 0.0028 - val_acc: 2.4349e-04\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 5s 557us/step - loss: 0.0032 - acc: 1.0435e-04 - val_loss: 0.0033 - val_acc: 2.4349e-04\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 5s 495us/step - loss: 0.0032 - acc: 1.0435e-04 - val_loss: 0.0023 - val_acc: 2.4349e-04\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0030 - acc: 1.0435e-04 - val_loss: 0.0026 - val_acc: 2.4349e-04\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0030 - acc: 1.0435e-04 - val_loss: 0.0029 - val_acc: 2.4349e-04\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 4s 469us/step - loss: 0.0030 - acc: 1.0435e-04 - val_loss: 0.0025 - val_acc: 2.4349e-04\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0029 - acc: 1.0435e-04 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 5s 479us/step - loss: 0.0030 - acc: 1.0435e-04 - val_loss: 0.0027 - val_acc: 2.4349e-04\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 5s 498us/step - loss: 0.0028 - acc: 1.0435e-04 - val_loss: 0.0023 - val_acc: 2.4349e-04\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0027 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0027 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0027 - acc: 1.0435e-04 - val_loss: 0.0023 - val_acc: 2.4349e-04\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0026 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0024 - acc: 1.0435e-04 - val_loss: 0.0025 - val_acc: 2.4349e-04\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0024 - acc: 1.0435e-04 - val_loss: 0.0032 - val_acc: 2.4349e-04\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0025 - acc: 1.0435e-04 - val_loss: 0.0032 - val_acc: 2.4349e-04\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 465us/step - loss: 0.0024 - acc: 1.0435e-04 - val_loss: 0.0033 - val_acc: 2.4349e-04\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0023 - acc: 1.0435e-04 - val_loss: 0.0034 - val_acc: 2.4349e-04\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 5s 470us/step - loss: 0.0023 - acc: 1.0435e-04 - val_loss: 0.0036 - val_acc: 2.4349e-04\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0024 - acc: 1.0435e-04 - val_loss: 0.0048 - val_acc: 2.4349e-04\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 465us/step - loss: 0.0023 - acc: 1.0435e-04 - val_loss: 0.0038 - val_acc: 2.4349e-04\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 5s 475us/step - loss: 0.0022 - acc: 1.0435e-04 - val_loss: 0.0035 - val_acc: 2.4349e-04\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 468us/step - loss: 0.0023 - acc: 1.0435e-04 - val_loss: 0.0037 - val_acc: 2.4349e-04\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9583/9583 [==============================] - 4s 465us/step - loss: 0.0023 - acc: 1.0435e-04 - val_loss: 0.0042 - val_acc: 2.4349e-04\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0039 - val_acc: 2.4349e-04\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0044 - val_acc: 2.4349e-04\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0047 - val_acc: 2.4349e-04\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0045 - val_acc: 2.4349e-04\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0046 - val_acc: 2.4349e-04\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0048 - val_acc: 2.4349e-04\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0022 - acc: 1.0435e-04 - val_loss: 0.0047 - val_acc: 2.4349e-04\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 0.0052 - val_acc: 2.4349e-04\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 0.0065 - val_acc: 2.4349e-04\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 0.0049 - val_acc: 2.4349e-04\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0019 - acc: 1.0435e-04 - val_loss: 0.0058 - val_acc: 2.4349e-04\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 0.0054 - val_acc: 2.4349e-04\n",
      "-20.4290881508731\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_17 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 6s 606us/step - loss: 0.2755 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0141 - acc: 1.0435e-04 - val_loss: 0.0023 - val_acc: 2.4349e-04\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0076 - acc: 1.0435e-04 - val_loss: 0.0019 - val_acc: 2.4349e-04\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0058 - acc: 1.0435e-04 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0051 - acc: 1.0435e-04 - val_loss: 0.0036 - val_acc: 2.4349e-04\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0046 - acc: 1.0435e-04 - val_loss: 0.0037 - val_acc: 2.4349e-04\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0042 - acc: 1.0435e-04 - val_loss: 0.0040 - val_acc: 2.4349e-04\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0037 - acc: 1.0435e-04 - val_loss: 0.0047 - val_acc: 2.4349e-04\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0032 - acc: 1.0435e-04 - val_loss: 0.0042 - val_acc: 2.4349e-04\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0031 - acc: 1.0435e-04 - val_loss: 0.0054 - val_acc: 2.4349e-04\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0030 - acc: 1.0435e-04 - val_loss: 0.0051 - val_acc: 2.4349e-04\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0029 - acc: 1.0435e-04 - val_loss: 0.0033 - val_acc: 2.4349e-04\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0027 - acc: 1.0435e-04 - val_loss: 0.0036 - val_acc: 2.4349e-04\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0028 - acc: 1.0435e-04 - val_loss: 0.0027 - val_acc: 2.4349e-04\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0027 - acc: 1.0435e-04 - val_loss: 0.0032 - val_acc: 2.4349e-04\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0025 - acc: 1.0435e-04 - val_loss: 0.0042 - val_acc: 2.4349e-04\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0024 - acc: 1.0435e-04 - val_loss: 0.0026 - val_acc: 2.4349e-04\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 5s 472us/step - loss: 0.0023 - acc: 1.0435e-04 - val_loss: 0.0036 - val_acc: 2.4349e-04\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0023 - acc: 1.0435e-04 - val_loss: 0.0013 - val_acc: 2.4349e-04\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 5s 488us/step - loss: 0.0024 - acc: 1.0435e-04 - val_loss: 0.0037 - val_acc: 2.4349e-04\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 468us/step - loss: 0.0022 - acc: 1.0435e-04 - val_loss: 0.0025 - val_acc: 2.4349e-04\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0022 - acc: 1.0435e-04 - val_loss: 0.0038 - val_acc: 2.4349e-04\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0021 - val_acc: 2.4349e-04\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 0.0037 - val_acc: 2.4349e-04\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0030 - val_acc: 2.4349e-04\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 0.0051 - val_acc: 2.4349e-04\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0011 - val_acc: 2.4349e-04\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 0.0026 - val_acc: 2.4349e-04\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 0.0034 - val_acc: 2.4349e-04\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9583/9583 [==============================] - 4s 468us/step - loss: 0.0019 - acc: 1.0435e-04 - val_loss: 0.0032 - val_acc: 2.4349e-04\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0019 - acc: 1.0435e-04 - val_loss: 0.0029 - val_acc: 2.4349e-04\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0019 - acc: 1.0435e-04 - val_loss: 0.0019 - val_acc: 2.4349e-04\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0018 - acc: 1.0435e-04 - val_loss: 0.0036 - val_acc: 2.4349e-04\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0018 - acc: 1.0435e-04 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0018 - acc: 1.0435e-04 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0029 - val_acc: 2.4349e-04\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0019 - val_acc: 2.4349e-04\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 5s 522us/step - loss: 0.0018 - acc: 1.0435e-04 - val_loss: 0.0036 - val_acc: 2.4349e-04\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 7s 709us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 7s 693us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 6s 593us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 0.0027 - val_acc: 2.4349e-04\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 5s 492us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0025 - val_acc: 2.4349e-04\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 5s 484us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 5s 474us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0035 - val_acc: 2.4349e-04\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 5s 470us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 0.0025 - val_acc: 2.4349e-04\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 467us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0035 - val_acc: 2.4349e-04\n",
      "-76.44243374360624\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_19 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 6s 622us/step - loss: 0.0844 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0090 - acc: 2.0870e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0059 - acc: 2.0870e-04 - val_loss: 7.5466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0048 - acc: 2.0870e-04 - val_loss: 9.7218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0042 - acc: 2.0870e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0037 - acc: 2.0870e-04 - val_loss: 6.9288e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0034 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0031 - acc: 2.0870e-04 - val_loss: 7.5715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0028 - acc: 2.0870e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0027 - acc: 2.0870e-04 - val_loss: 3.2195e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 4s 467us/step - loss: 0.0028 - acc: 2.0870e-04 - val_loss: 3.0465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 5s 481us/step - loss: 0.0026 - acc: 2.0870e-04 - val_loss: 3.3988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0026 - acc: 2.0870e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0024 - acc: 2.0870e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 5s 470us/step - loss: 0.0023 - acc: 2.0870e-04 - val_loss: 8.8060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0023 - acc: 2.0870e-04 - val_loss: 4.9632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0021 - acc: 2.0870e-04 - val_loss: 3.0614e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 4s 465us/step - loss: 0.0023 - acc: 2.0870e-04 - val_loss: 5.1583e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0022 - acc: 2.0870e-04 - val_loss: 5.7450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 5s 472us/step - loss: 0.0022 - acc: 2.0870e-04 - val_loss: 2.6488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0020 - acc: 2.0870e-04 - val_loss: 3.0360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0020 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 2.7962e-04 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 6.1734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0020 - acc: 2.0870e-04 - val_loss: 3.4688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 3.2872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 469us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 469us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0018 - acc: 2.0870e-04 - val_loss: 3.7343e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 468us/step - loss: 0.0018 - acc: 2.0870e-04 - val_loss: 2.5398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0018 - acc: 2.0870e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0018 - acc: 2.0870e-04 - val_loss: 4.0592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 2.4265e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 467us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 2.6545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 6.9377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0016 - acc: 2.0870e-04 - val_loss: 7.1970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 3.6254e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 4s 469us/step - loss: 0.0016 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 2.1166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0016 - acc: 2.0870e-04 - val_loss: 2.0040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 4s 467us/step - loss: 0.0016 - acc: 2.0870e-04 - val_loss: 2.3321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 9.3948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0016 - acc: 2.0870e-04 - val_loss: 2.1329e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0015 - acc: 2.0870e-04 - val_loss: 2.0068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 4s 465us/step - loss: 0.0015 - acc: 2.0870e-04 - val_loss: 2.8105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 5s 478us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 2.0546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 469us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 2.1276e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 467us/step - loss: 0.0016 - acc: 2.0870e-04 - val_loss: 4.1286e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 466us/step - loss: 0.0017 - acc: 2.0870e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0015 - acc: 2.0870e-04 - val_loss: 9.3178e-04 - val_acc: 0.0000e+00\n",
      "-26.040481055876697\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 6s 629us/step - loss: 0.1436 - acc: 2.0870e-04 - val_loss: 0.0059 - val_acc: 7.3046e-04\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0139 - acc: 2.0870e-04 - val_loss: 0.0013 - val_acc: 7.3046e-04\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0087 - acc: 2.0870e-04 - val_loss: 0.0013 - val_acc: 7.3046e-04\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 462us/step - loss: 0.0064 - acc: 2.0870e-04 - val_loss: 8.0829e-04 - val_acc: 7.3046e-04\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0053 - acc: 2.0870e-04 - val_loss: 6.8535e-04 - val_acc: 7.3046e-04\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0044 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 7.3046e-04\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0040 - acc: 2.0870e-04 - val_loss: 8.4751e-04 - val_acc: 7.3046e-04\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0037 - acc: 2.0870e-04 - val_loss: 7.6184e-04 - val_acc: 7.3046e-04\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0034 - acc: 2.0870e-04 - val_loss: 7.7986e-04 - val_acc: 7.3046e-04\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0034 - acc: 2.0870e-04 - val_loss: 7.1852e-04 - val_acc: 7.3046e-04\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0033 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 7.3046e-04\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0031 - acc: 2.0870e-04 - val_loss: 8.8875e-04 - val_acc: 7.3046e-04\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0030 - acc: 2.0870e-04 - val_loss: 7.7918e-04 - val_acc: 7.3046e-04\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0030 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 7.3046e-04\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0029 - acc: 2.0870e-04 - val_loss: 6.5301e-04 - val_acc: 7.3046e-04\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0028 - acc: 2.0870e-04 - val_loss: 9.7854e-04 - val_acc: 7.3046e-04\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0028 - acc: 2.0870e-04 - val_loss: 8.5380e-04 - val_acc: 7.3046e-04\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0027 - acc: 2.0870e-04 - val_loss: 8.7739e-04 - val_acc: 7.3046e-04\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 5s 532us/step - loss: 0.0027 - acc: 2.0870e-04 - val_loss: 7.7994e-04 - val_acc: 7.3046e-04\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0026 - acc: 2.0870e-04 - val_loss: 7.1197e-04 - val_acc: 7.3046e-04\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0025 - acc: 2.0870e-04 - val_loss: 7.7775e-04 - val_acc: 7.3046e-04\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0025 - acc: 2.0870e-04 - val_loss: 8.2405e-04 - val_acc: 7.3046e-04\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0025 - acc: 2.0870e-04 - val_loss: 8.1073e-04 - val_acc: 7.3046e-04\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 0.0023 - acc: 2.0870e-04 - val_loss: 8.5757e-04 - val_acc: 7.3046e-04\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0024 - acc: 2.0870e-04 - val_loss: 9.5414e-04 - val_acc: 7.3046e-04\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0023 - acc: 2.0870e-04 - val_loss: 7.6613e-04 - val_acc: 7.3046e-04\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 0.0025 - acc: 2.0870e-04 - val_loss: 9.7956e-04 - val_acc: 7.3046e-04\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0023 - acc: 2.0870e-04 - val_loss: 9.6962e-04 - val_acc: 7.3046e-04\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0022 - acc: 2.0870e-04 - val_loss: 0.0010 - val_acc: 7.3046e-04\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0023 - acc: 2.0870e-04 - val_loss: 8.4570e-04 - val_acc: 7.3046e-04\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 453us/step - loss: 0.0022 - acc: 2.0870e-04 - val_loss: 9.9263e-04 - val_acc: 7.3046e-04\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0021 - acc: 2.0870e-04 - val_loss: 0.0010 - val_acc: 7.3046e-04\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0022 - acc: 2.0870e-04 - val_loss: 9.7191e-04 - val_acc: 7.3046e-04\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0022 - acc: 2.0870e-04 - val_loss: 9.7026e-04 - val_acc: 7.3046e-04\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0021 - acc: 2.0870e-04 - val_loss: 9.9145e-04 - val_acc: 7.3046e-04\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0022 - acc: 2.0870e-04 - val_loss: 9.0447e-04 - val_acc: 7.3046e-04\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 453us/step - loss: 0.0020 - acc: 2.0870e-04 - val_loss: 0.0010 - val_acc: 7.3046e-04\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 4s 453us/step - loss: 0.0021 - acc: 2.0870e-04 - val_loss: 9.5555e-04 - val_acc: 7.3046e-04\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0020 - acc: 2.0870e-04 - val_loss: 0.0012 - val_acc: 7.3046e-04\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 0.0014 - val_acc: 7.3046e-04\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 4s 441us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 0.0012 - val_acc: 7.3046e-04\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 7.3046e-04\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 4s 441us/step - loss: 0.0020 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 7.3046e-04\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0021 - acc: 2.0870e-04 - val_loss: 0.0012 - val_acc: 7.3046e-04\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0022 - acc: 2.0870e-04 - val_loss: 0.0012 - val_acc: 7.3046e-04\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 4s 451us/step - loss: 0.0018 - acc: 2.0870e-04 - val_loss: 0.0013 - val_acc: 7.3046e-04\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 0.0012 - val_acc: 7.3046e-04\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 7.3046e-04\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0019 - acc: 2.0870e-04 - val_loss: 0.0013 - val_acc: 7.3046e-04\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0020 - acc: 2.0870e-04 - val_loss: 0.0011 - val_acc: 7.3046e-04\n",
      "-70.3901843053463\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_23 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 6s 628us/step - loss: 0.0851 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 453us/step - loss: 0.0078 - acc: 1.0435e-04 - val_loss: 0.0037 - val_acc: 2.4349e-04\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0049 - acc: 1.0435e-04 - val_loss: 0.0012 - val_acc: 2.4349e-04\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 452us/step - loss: 0.0040 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0033 - acc: 1.0435e-04 - val_loss: 5.2558e-04 - val_acc: 2.4349e-04\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0026 - acc: 1.0435e-04 - val_loss: 0.0020 - val_acc: 2.4349e-04\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 5s 476us/step - loss: 0.0024 - acc: 1.0435e-04 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0022 - acc: 1.0435e-04 - val_loss: 5.5101e-04 - val_acc: 2.4349e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 0.0023 - val_acc: 2.4349e-04\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0018 - acc: 1.0435e-04 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0018 - acc: 1.0435e-04 - val_loss: 0.0013 - val_acc: 2.4349e-04\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0011 - val_acc: 2.4349e-04\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0025 - val_acc: 2.4349e-04\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0038 - val_acc: 2.4349e-04\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 4s 463us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 5.3069e-04 - val_acc: 2.4349e-04\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 5s 495us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 5.3257e-04 - val_acc: 2.4349e-04\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 6s 576us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0019 - val_acc: 2.4349e-04\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 5s 545us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 5s 563us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 5s 522us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 8.1148e-04 - val_acc: 2.4349e-04\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 5s 494us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 9.5357e-04 - val_acc: 2.4349e-04\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 4s 451us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 7.0353e-04 - val_acc: 2.4349e-04\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 452us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 5.1325e-04 - val_acc: 2.4349e-04\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 9.7914e-04 - val_acc: 2.4349e-04\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 452us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 5.4314e-04 - val_acc: 2.4349e-04\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 5.1083e-04 - val_acc: 2.4349e-04\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 3.6449e-04 - val_acc: 2.4349e-04\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 6.9925e-04 - val_acc: 2.4349e-04\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 6.5606e-04 - val_acc: 2.4349e-04\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 5.9800e-04 - val_acc: 2.4349e-04\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 8.9625e-04 - val_acc: 2.4349e-04\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0013 - val_acc: 2.4349e-04\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0010 - val_acc: 2.4349e-04\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 3.9450e-04 - val_acc: 2.4349e-04\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 7.7072e-04 - val_acc: 2.4349e-04\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0010 - acc: 1.0435e-04 - val_loss: 7.7329e-04 - val_acc: 2.4349e-04\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0010 - acc: 1.0435e-04 - val_loss: 7.4770e-04 - val_acc: 2.4349e-04\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 9.9248e-04 - acc: 1.0435e-04 - val_loss: 7.3779e-04 - val_acc: 2.4349e-04\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 9.9706e-04 - acc: 1.0435e-04 - val_loss: 3.5459e-04 - val_acc: 2.4349e-04\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 452us/step - loss: 0.0010 - acc: 1.0435e-04 - val_loss: 5.2520e-04 - val_acc: 2.4349e-04\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 9.5972e-04 - acc: 1.0435e-04 - val_loss: 6.0800e-04 - val_acc: 2.4349e-04\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 9.6322e-04 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "-39.318038312263496\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9583/9583 [==============================] - 6s 637us/step - loss: 0.0951 - acc: 0.0000e+00 - val_loss: 8.1505e-04 - val_acc: 4.8697e-04\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 441us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 4.8697e-04\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 7.7283e-04 - val_acc: 4.8697e-04\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0068 - acc: 0.0000e+00 - val_loss: 8.3465e-04 - val_acc: 4.8697e-04\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0063 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 4.8697e-04\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 4.8697e-04\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 5s 523us/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 4.8697e-04\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 5s 567us/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 4.8697e-04\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 5s 483us/step - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 4.8697e-04\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 5s 476us/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 4.8697e-04\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 5s 475us/step - loss: 0.0039 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 4.8697e-04\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 5s 484us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 4.8697e-04\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 5s 493us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 4.8697e-04\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 4.8697e-04\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 4.8697e-04\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 4.8697e-04\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 4.8697e-04\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 4s 469us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 4.8697e-04\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 4.8697e-04\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 5s 492us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 4.8697e-04\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 4.8697e-04\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 4.8697e-04\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 4.8697e-04\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 4.8697e-04\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 4.8697e-04\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 4.8697e-04\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 4.8697e-04\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 4.8697e-04\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 4.8697e-04\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 4.8697e-04\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 451us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 4.8697e-04\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 4.8697e-04\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 4s 451us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 4.8697e-04\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 4.8697e-04\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 4.8697e-04\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 4.8697e-04\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 4.8697e-04\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 4s 452us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 4.8697e-04\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0077 - val_acc: 4.8697e-04\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 4.8697e-04\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0073 - val_acc: 4.8697e-04\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 4.8697e-04\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 4.8697e-04\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 4.8697e-04\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 4.8697e-04\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 4s 441us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 4.8697e-04\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0103 - val_acc: 4.8697e-04\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0123 - val_acc: 4.8697e-04\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0136 - val_acc: 4.8697e-04\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 441us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0148 - val_acc: 4.8697e-04\n",
      "-45.22394765635183\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 6s 636us/step - loss: 0.1557 - acc: 4.1741e-04 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0115 - acc: 4.1741e-04 - val_loss: 9.4679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0071 - acc: 4.1741e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0062 - acc: 4.1741e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0051 - acc: 4.1741e-04 - val_loss: 8.3626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0045 - acc: 4.1741e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0040 - acc: 4.1741e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0039 - acc: 4.1741e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0038 - acc: 4.1741e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0036 - acc: 4.1741e-04 - val_loss: 7.7851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0034 - acc: 4.1741e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0032 - acc: 4.1741e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 4s 465us/step - loss: 0.0032 - acc: 4.1741e-04 - val_loss: 9.7913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0034 - acc: 4.1741e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0030 - acc: 4.1741e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0029 - acc: 4.1741e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0028 - acc: 4.1741e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0029 - acc: 4.1741e-04 - val_loss: 6.0114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0027 - acc: 4.1741e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0028 - acc: 4.1741e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0026 - acc: 4.1741e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0025 - acc: 4.1741e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0024 - acc: 4.1741e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0024 - acc: 4.1741e-04 - val_loss: 8.2093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 460us/step - loss: 0.0023 - acc: 4.1741e-04 - val_loss: 3.7849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0023 - acc: 4.1741e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0024 - acc: 4.1741e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 451us/step - loss: 0.0024 - acc: 4.1741e-04 - val_loss: 4.8040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0022 - acc: 4.1741e-04 - val_loss: 9.1644e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 451us/step - loss: 0.0022 - acc: 4.1741e-04 - val_loss: 6.5019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0021 - acc: 4.1741e-04 - val_loss: 6.7378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0021 - acc: 4.1741e-04 - val_loss: 7.1505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0021 - acc: 4.1741e-04 - val_loss: 8.6636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0021 - acc: 4.1741e-04 - val_loss: 5.7035e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0020 - acc: 4.1741e-04 - val_loss: 5.3178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0020 - acc: 4.1741e-04 - val_loss: 6.0769e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0021 - acc: 4.1741e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 5s 489us/step - loss: 0.0021 - acc: 4.1741e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0020 - acc: 4.1741e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0019 - acc: 4.1741e-04 - val_loss: 4.7267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0019 - acc: 4.1741e-04 - val_loss: 7.9323e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 5s 476us/step - loss: 0.0020 - acc: 4.1741e-04 - val_loss: 7.5168e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0020 - acc: 4.1741e-04 - val_loss: 2.8249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0020 - acc: 4.1741e-04 - val_loss: 4.5087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0021 - acc: 4.1741e-04 - val_loss: 3.0181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0018 - acc: 4.1741e-04 - val_loss: 3.0257e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 0.0019 - acc: 4.1741e-04 - val_loss: 5.0799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0018 - acc: 4.1741e-04 - val_loss: 9.3006e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 5s 499us/step - loss: 0.0020 - acc: 4.1741e-04 - val_loss: 3.5002e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0018 - acc: 4.1741e-04 - val_loss: 3.2335e-04 - val_acc: 0.0000e+00\n",
      "-37.197348625474035\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_29 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 6s 645us/step - loss: 0.0627 - acc: 0.0000e+00 - val_loss: 0.0147 - val_acc: 2.4349e-04\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 451us/step - loss: 0.0073 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 2.4349e-04\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 2.4349e-04\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 2.4349e-04\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 4s 440us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 2.4349e-041s - loss: 0.0020 - acc: 0.00\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 2.4349e-04\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 2.4349e-04\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 9.6905e-04 - val_acc: 2.4349e-04\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 4s 452us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 2.4349e-04\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 4s 461us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 9.2758e-04 - val_acc: 2.4349e-04\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 2.4349e-04\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 4s 441us/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 2.4349e-04\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 5s 521us/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 6.1966e-04 - val_acc: 2.4349e-04\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 9.9581e-04 - val_acc: 2.4349e-04\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 9.8466e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 7.4381e-04 - val_acc: 2.4349e-04\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 9.6794e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 2.4349e-04\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 9.5204e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 4s 451us/step - loss: 9.6585e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 9.4201e-04 - acc: 0.0000e+00 - val_loss: 6.7230e-04 - val_acc: 2.4349e-04\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 442us/step - loss: 8.8496e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 2.4349e-04\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 8.8340e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 8.9555e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 8.7473e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 8.4822e-04 - acc: 0.0000e+00 - val_loss: 8.8484e-04 - val_acc: 2.4349e-04\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 8.4553e-04 - acc: 0.0000e+00 - val_loss: 3.9457e-04 - val_acc: 2.4349e-04\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 8.1399e-04 - acc: 0.0000e+00 - val_loss: 7.6590e-04 - val_acc: 2.4349e-04\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 8.2625e-04 - acc: 0.0000e+00 - val_loss: 6.5858e-04 - val_acc: 2.4349e-04\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 8.1841e-04 - acc: 0.0000e+00 - val_loss: 2.7972e-04 - val_acc: 2.4349e-04\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 8.4455e-04 - acc: 0.0000e+00 - val_loss: 6.8728e-04 - val_acc: 2.4349e-04\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 8.4131e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 2.4349e-04\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 8.0836e-04 - acc: 0.0000e+00 - val_loss: 2.3659e-04 - val_acc: 2.4349e-04\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 7.6539e-04 - acc: 0.0000e+00 - val_loss: 4.9800e-04 - val_acc: 2.4349e-04\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 458us/step - loss: 7.5754e-04 - acc: 0.0000e+00 - val_loss: 7.8257e-04 - val_acc: 2.4349e-04\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 7.3674e-04 - acc: 0.0000e+00 - val_loss: 7.2936e-04 - val_acc: 2.4349e-04\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 7.8955e-04 - acc: 0.0000e+00 - val_loss: 2.9785e-04 - val_acc: 2.4349e-04\n",
      "-35.418588302004174\n",
      "Amount of features = 19\n",
      "Amount of training data = 13763\n",
      "Amount of testing data = 5899\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_31 (Conv1D)           (None, 71, 64)            2496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 34, 64)            8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 250)               272250    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 283,253\n",
      "Trainable params: 283,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9583 samples, validate on 4107 samples\n",
      "Epoch 1/50\n",
      "9583/9583 [==============================] - 6s 654us/step - loss: 0.0527 - acc: 1.0435e-04 - val_loss: 0.0089 - val_acc: 2.4349e-04\n",
      "Epoch 2/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0070 - acc: 1.0435e-04 - val_loss: 0.0059 - val_acc: 2.4349e-04\n",
      "Epoch 3/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0047 - acc: 1.0435e-04 - val_loss: 0.0022 - val_acc: 2.4349e-04\n",
      "Epoch 4/50\n",
      "9583/9583 [==============================] - 4s 443us/step - loss: 0.0039 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 5/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0033 - acc: 1.0435e-04 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 6/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 0.0029 - acc: 1.0435e-04 - val_loss: 0.0014 - val_acc: 2.4349e-04\n",
      "Epoch 7/50\n",
      "9583/9583 [==============================] - 4s 456us/step - loss: 0.0026 - acc: 1.0435e-04 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 8/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0024 - acc: 1.0435e-04 - val_loss: 0.0017 - val_acc: 2.4349e-04\n",
      "Epoch 9/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0022 - acc: 1.0435e-04 - val_loss: 0.0012 - val_acc: 2.4349e-04\n",
      "Epoch 10/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0021 - acc: 1.0435e-04 - val_loss: 8.8327e-04 - val_acc: 2.4349e-04\n",
      "Epoch 11/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0020 - acc: 1.0435e-04 - val_loss: 9.7188e-04 - val_acc: 2.4349e-04\n",
      "Epoch 12/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0018 - acc: 1.0435e-04 - val_loss: 9.7404e-04 - val_acc: 2.4349e-04\n",
      "Epoch 13/50\n",
      "9583/9583 [==============================] - 5s 471us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 9.8896e-04 - val_acc: 2.4349e-04\n",
      "Epoch 14/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0024 - val_acc: 2.4349e-04\n",
      "Epoch 15/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0017 - acc: 1.0435e-04 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 16/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 7.6772e-04 - val_acc: 2.4349e-04\n",
      "Epoch 17/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0016 - acc: 1.0435e-04 - val_loss: 0.0018 - val_acc: 2.4349e-04\n",
      "Epoch 18/50\n",
      "9583/9583 [==============================] - 4s 457us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 8.4349e-04 - val_acc: 2.4349e-04\n",
      "Epoch 19/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0015 - acc: 1.0435e-04 - val_loss: 0.0015 - val_acc: 2.4349e-04\n",
      "Epoch 20/50\n",
      "9583/9583 [==============================] - 4s 464us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 0.0016 - val_acc: 2.4349e-04\n",
      "Epoch 21/50\n",
      "9583/9583 [==============================] - 4s 455us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 8.5307e-04 - val_acc: 2.4349e-04\n",
      "Epoch 22/50\n",
      "9583/9583 [==============================] - 4s 465us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 6.3297e-04 - val_acc: 2.4349e-04\n",
      "Epoch 23/50\n",
      "9583/9583 [==============================] - 5s 483us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 5.1889e-04 - val_acc: 2.4349e-04\n",
      "Epoch 24/50\n",
      "9583/9583 [==============================] - 4s 448us/step - loss: 0.0014 - acc: 1.0435e-04 - val_loss: 9.0436e-04 - val_acc: 2.4349e-04\n",
      "Epoch 25/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 3.4617e-04 - val_acc: 2.4349e-04\n",
      "Epoch 26/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0013 - acc: 1.0435e-04 - val_loss: 5.4766e-04 - val_acc: 2.4349e-04\n",
      "Epoch 27/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 8.6032e-04 - val_acc: 2.4349e-04\n",
      "Epoch 28/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0011 - val_acc: 2.4349e-04\n",
      "Epoch 29/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 8.7104e-04 - val_acc: 2.4349e-04\n",
      "Epoch 30/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 4.5575e-04 - val_acc: 2.4349e-04\n",
      "Epoch 31/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 0.0010 - val_acc: 2.4349e-04\n",
      "Epoch 32/50\n",
      "9583/9583 [==============================] - 5s 473us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 5.5324e-04 - val_acc: 2.4349e-04\n",
      "Epoch 33/50\n",
      "9583/9583 [==============================] - 4s 459us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 4.3120e-04 - val_acc: 2.4349e-04\n",
      "Epoch 34/50\n",
      "9583/9583 [==============================] - 4s 445us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0011 - val_acc: 2.4349e-04\n",
      "Epoch 35/50\n",
      "9583/9583 [==============================] - 4s 453us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 3.8989e-04 - val_acc: 2.4349e-04\n",
      "Epoch 36/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 5.2924e-04 - val_acc: 2.4349e-04\n",
      "Epoch 37/50\n",
      "9583/9583 [==============================] - 4s 452us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 4.0043e-04 - val_acc: 2.4349e-04\n",
      "Epoch 38/50\n",
      "9583/9583 [==============================] - 4s 444us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 2.5487e-04 - val_acc: 2.4349e-04\n",
      "Epoch 39/50\n",
      "9583/9583 [==============================] - 5s 474us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0011 - val_acc: 2.4349e-04\n",
      "Epoch 40/50\n",
      "9583/9583 [==============================] - 4s 469us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 0.0010 - val_acc: 2.4349e-04\n",
      "Epoch 41/50\n",
      "9583/9583 [==============================] - 4s 454us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 2.8522e-04 - val_acc: 2.4349e-04\n",
      "Epoch 42/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0010 - acc: 1.0435e-04 - val_loss: 6.2339e-04 - val_acc: 2.4349e-04\n",
      "Epoch 43/50\n",
      "9583/9583 [==============================] - 5s 479us/step - loss: 0.0010 - acc: 1.0435e-04 - val_loss: 8.0020e-04 - val_acc: 2.4349e-04\n",
      "Epoch 44/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0010 - acc: 1.0435e-04 - val_loss: 5.7912e-04 - val_acc: 2.4349e-04\n",
      "Epoch 45/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 9.4871e-04 - acc: 1.0435e-04 - val_loss: 2.5643e-04 - val_acc: 2.4349e-04\n",
      "Epoch 46/50\n",
      "9583/9583 [==============================] - 4s 450us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 3.7901e-04 - val_acc: 2.4349e-04\n",
      "Epoch 47/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0012 - acc: 1.0435e-04 - val_loss: 4.0839e-04 - val_acc: 2.4349e-04\n",
      "Epoch 48/50\n",
      "9583/9583 [==============================] - 4s 446us/step - loss: 9.8740e-04 - acc: 1.0435e-04 - val_loss: 9.7703e-04 - val_acc: 2.4349e-04\n",
      "Epoch 49/50\n",
      "9583/9583 [==============================] - 4s 447us/step - loss: 0.0010 - acc: 1.0435e-04 - val_loss: 3.0216e-04 - val_acc: 2.4349e-04\n",
      "Epoch 50/50\n",
      "9583/9583 [==============================] - 4s 449us/step - loss: 0.0011 - acc: 1.0435e-04 - val_loss: 6.5551e-04 - val_acc: 2.4349e-04\n",
      "-24.48660378701958\n"
     ]
    }
   ],
   "source": [
    "currency_list=[ 'GBP Curncy',\n",
    " 'JPY Curncy',\n",
    " 'EUR Curncy',\n",
    " 'CAD Curncy',\n",
    " 'NZD Curncy',\n",
    " 'SEK Curncy',\n",
    " 'AUD Curncy',\n",
    " 'CHF Curncy',\n",
    " 'NOK Curncy',\n",
    " 'ZAR Curncy']\n",
    "predictcur=portfolio(currency_list,file = 'FX-5-merg.xlsx',seq_len = seq_len,shape = [seq_len, 19, 1],neurons = [256, 256, 32, 1],dropout = 0.2,decay = decay,\n",
    "              epochs = 50,ma=[12, 72, 144],bollinger=[12, 72, 144],exp_ma=[12, 72, 144],ma_conv=[[26,12]],split=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MarkowitzWithTransactionsCost(n,mu,GT,x0,w,gamma,f,g):\n",
    "    # Upper bound on the traded amount\n",
    "    w0 = w+sum(x0)\n",
    "    u = n*[w0]\n",
    "\n",
    "    with Model(\"Markowitz portfolio with transaction costs\") as M:\n",
    "        #M.setLogHandler(sys.stdout)\n",
    "\n",
    "        # Defines the variables. No shortselling is allowed.\n",
    "        x = M.variable(\"x\", n, Domain.greaterThan(0.0))\n",
    "        #x = M.variable(\"x\", n, Domain.lessThan(0.0))\n",
    "        #x = M.variable(\"x\", n, Domain.inRange(-3., 3.))\n",
    "        \n",
    "        # Additional \"helper\" variables \n",
    "        z = M.variable(\"z\", n, Domain.unbounded())   \n",
    "        # Binary variables\n",
    "        y = M.variable(\"y\", n, Domain.binary())\n",
    "\n",
    "        #  Maximize expected return\n",
    "        M.objective('obj', ObjectiveSense.Maximize, Expr.dot(mu,x))\n",
    "\n",
    "        # Invest amount + transactions costs = initial wealth\n",
    "        M.constraint('budget', Expr.add([ Expr.sum(x), Expr.dot(f,y),Expr.dot(g,z)] ), Domain.equalsTo(w0))\n",
    "\n",
    "        # Imposes a bound on the risk\n",
    "        M.constraint('risk', Expr.vstack( gamma,Expr.mul(GT,x)), Domain.inQCone())\n",
    "\n",
    "        # z >= |x-x0| \n",
    "        M.constraint('buy', Expr.sub(z,Expr.sub(x,x0)),Domain.greaterThan(0.0))\n",
    "        M.constraint('sell', Expr.sub(z,Expr.sub(x0,x)),Domain.greaterThan(0.0))\n",
    "        # Alternatively, formulate the two constraints as\n",
    "        #M.constraint('trade', Expr.hstack(z,Expr.sub(x,x0)), Domain.inQcone())\n",
    "\n",
    "        # Constraints for turning y off and on. z-diag(u)*y<=0 i.e. z_j <= u_j*y_j\n",
    "        M.constraint('y_on_off', Expr.sub(z,Expr.mulElm(u,y)), Domain.lessThan(0.0))\n",
    "\n",
    "        # Integer optimization problems can be very hard to solve so limiting the \n",
    "        # maximum amount of time is a valuable safe guard\n",
    "        M.setSolverParam('mioMaxTime', 10000.0) \n",
    "        M.solve()\n",
    "\n",
    "        return (np.dot(mu,x.level()), x.level())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance(n,previous_ret,x0,w,mu,gamma=1):\n",
    "    GT=np.cov(previous_ret)\n",
    "    f = n*[0.0000]\n",
    "    g = n*[0.005]\n",
    "    _,weights=MarkowitzWithTransactionsCost(n,mu,GT,x0,w,gamma,f,g)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_diff(data):\n",
    "    return np.diff(np.log(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(prices, predictions, initial_weights):\n",
    "    t_prices = len(prices[1,:])\n",
    "    t_predictions = len(predictions)\n",
    "    length_past = t_prices - t_predictions\n",
    "    returns = np.apply_along_axis(log_diff, 1, prices)\n",
    "    prediction_return = []\n",
    "    port_return=1\n",
    "    for k in range(t_predictions):\n",
    "        prediction_return.append(np.log(predictions[k]/prices[:,length_past+k-1]))\n",
    "    weights = initial_weights\n",
    "    portfolio_return = []\n",
    "    prev_weight = weights\n",
    "    for i in range(0,t_predictions-1):\n",
    "    #for i in range(0,1000):\n",
    "        predicted_return = prediction_return[i]\n",
    "        #predicted_return = returns[:,length_past+i-1]\n",
    "        previous_return = returns[:,length_past+i-1]\n",
    "        previous_returns = returns[:,0:(length_past+i-1)]\n",
    "        if i==0:\n",
    "            new_weight = rebalance(10,previous_returns,mu=predicted_return.tolist(),x0=prev_weight,w=0,gamma=5)\n",
    "        else:\n",
    "            new_weight = rebalance(10,previous_returns,mu=predicted_return.tolist(),x0=prev_weight,w=0,gamma=5)\n",
    "        period_return = np.dot(new_weight,returns[:,length_past+i])\n",
    "        port_return=port_return*(1+period_return)\n",
    "        portfolio_return.append(port_return)\n",
    "        prev_weight = new_weight\n",
    "        print(period_return)\n",
    "    return portfolio_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptimizeError",
     "evalue": "rescode.err_missing_license_file(1008): License cannot be located. The default search path is ';C:\\Users\\ishan\\mosek\\mosek.lic;'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mosek\\fusion\\impl\\_implementation.py\u001b[0m in \u001b[0;36m_task_1solve_ZSS\u001b[1;34m(self, remote, server, port)\u001b[0m\n\u001b[0;32m   3282\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3283\u001b[1;33m             \u001b[0mtrmcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3284\u001b[0m           \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutionsummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmosek\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreamtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mosek\\__init__.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   7626\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getlasterror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7627\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrescode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7628\u001b[0m       \u001b[0m__arg1_trmcode_return_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: rescode.err_missing_license_file(1008): License cannot be located. The default search path is ';C:\\Users\\ishan\\mosek\\mosek.lic;'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOptimizeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3f07c31b8c93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbacktest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_close\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictcur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-b6bde942fa3c>\u001b[0m in \u001b[0;36mbacktest\u001b[1;34m(prices, predictions, initial_weights)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprevious_returns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength_past\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mnew_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrebalance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprevious_returns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredicted_return\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprev_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mnew_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrebalance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprevious_returns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredicted_return\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprev_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-3dab9b839ff3>\u001b[0m in \u001b[0;36mrebalance\u001b[1;34m(n, previous_ret, x0, w, mu, gamma)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMarkowitzWithTransactionsCost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-c6235ea4c3c9>\u001b[0m in \u001b[0;36mMarkowitzWithTransactionsCost\u001b[1;34m(n, mu, GT, x0, w, gamma, f, g)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# maximum amount of time is a valuable safe guard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetSolverParam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mioMaxTime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mosek\\fusion\\impl\\_implementation.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   3812\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3813\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmosek_fusion_Model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_match_solve_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3814\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3815\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmosek_fusion_Model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_match_alt_solve_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3816\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve_alt_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mosek\\fusion\\impl\\_implementation.py\u001b[0m in \u001b[0;36m_solve_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4990\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flushSolutions_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4991\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__flush_1parameters_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4992\u001b[1;33m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_1solve_ZSS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4993\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__flush_1parameters_alt_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4994\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__flush_1parameters_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mosek\\fusion\\impl\\_implementation.py\u001b[0m in \u001b[0;36m_task_1solve_ZSS\u001b[1;34m(self, remote, server, port)\u001b[0m\n\u001b[0;32m   3284\u001b[0m           \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutionsummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmosek\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreamtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3285\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mmosek\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3286\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0mmosek_fusion_OptimizeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m         \u001b[0mnumcon\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnumcon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOptimizeError\u001b[0m: rescode.err_missing_license_file(1008): License cannot be located. The default search path is ';C:\\Users\\ishan\\mosek\\mosek.lic;'."
     ]
    }
   ],
   "source": [
    "x=backtest(df_close.T, predictcur, np.repeat(1/10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ba608aa7ada2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(x)\n",
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "    newp = denormalize(stock_name, normalized_value_p,predict=True)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test,predict=False)\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format(stock_name))\n",
    "    plt2.xlabel('5 Min ahead Forecast')\n",
    "    plt2.ylabel('Price')\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
